{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/submarinejuice/CP322-Final-Project-Group-9/blob/main/cp322_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-th1E27v0Hod",
        "outputId": "21bac953-afb7-42c3-c3b8-8b70d4d12cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (25.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: yfinance in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.66)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.5)\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.2)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.10.6)\n",
            "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.13.2)\n",
            "Requirement already satisfied: shap in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.50.0)\n",
            "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.20.0)\n",
            "Requirement already satisfied: requests>=2.31 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (4.4.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (5.28.3)\n",
            "Requirement already satisfied: websockets>=13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (0.62.1)\n",
            "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.12.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from numba>=0.54->shap) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Downloading dependencies\n",
        "%pip install --upgrade pip\n",
        "%pip install yfinance pandas numpy scikit-learn matplotlib seaborn shap tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocqzd2QLuJJ_",
        "outputId": "cf6b7e3a-efeb-4797-d4ac-4bb17aea0d55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  3 of 3 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (1509, 15)\n",
            "Columns: [('Close', 'AAPL'), ('Close', 'GOOGL'), ('Close', 'TSLA'), ('High', 'AAPL'), ('High', 'GOOGL'), ('High', 'TSLA'), ('Low', 'AAPL'), ('Low', 'GOOGL'), ('Low', 'TSLA'), ('Open', 'AAPL'), ('Open', 'GOOGL'), ('Open', 'TSLA'), ('Volume', 'AAPL'), ('Volume', 'GOOGL'), ('Volume', 'TSLA')]\n",
            "Date range: 2018-01-02 00:00:00 to 2023-12-29 00:00:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Attention, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Project Overview\n",
        "#\n",
        "# Neuro + Fintech + Financial Text Sentiment Predictor\n",
        "#\n",
        "# Goal: Predict Buy / Sell / Hold decisions by integrating multiple data modalities:\n",
        "# - Stock price data: historical OHLC, returns, moving averages, volatility indicators\n",
        "# - Financial news sentiment: daily sentiment scores derived from news headlines or articles\n",
        "# - Simulated cognitive features: attention, stress, risk appetite, confidence (used until a real dataset is available)\n",
        "#\n",
        "# This project demonstrates multi-modal machine learning by combining:\n",
        "# 1. Market numeric data (stocks)\n",
        "# 2. Textual data (financial news sentiment)\n",
        "# 3. Neuro-inspired cognitive signals\n",
        "#\n",
        "# Key Features of the Project:\n",
        "# - Temporal modeling: cognitive features and lagged news sentiment are sequence-dependent\n",
        "# - Multi-modal integration: numeric, textual, and simulated cognitive features feed into a single model\n",
        "# - Evaluation & Explainability: model performance measured via accuracy and F1-score, with feature importance explored using SHAP\n",
        "#\n",
        "# Objectives:\n",
        "# 1. Build a sequence-aware model (LSTM/GRU with attention) to predict trading actions\n",
        "# 2. Demonstrate non-obvious patterns by including temporal and multi-modal dependencies\n",
        "# 3. Perform ablation studies to quantify the contribution of cognitive and sentiment features\n",
        "# 4. Provide interpretable insights into feature importance and model behavior\n",
        "\n",
        "def get_stock_data(tickers, start_date, end_date):\n",
        "    \"\"\"Download real stock price data\"\"\"\n",
        "    data = yf.download(tickers, start=start_date, end=end_date, auto_adjust=True)\n",
        "    return data\n",
        "\n",
        "TICKERS = ['AAPL', 'TSLA', 'GOOGL']\n",
        "START_DATE = '2018-01-01'\n",
        "END_DATE = '2024-01-01'\n",
        "\n",
        "price_data = get_stock_data(TICKERS, START_DATE, END_DATE)\n",
        "print(f\"Data shape: {price_data.shape}\")\n",
        "print(f\"Columns: {price_data.columns.tolist()}\")\n",
        "print(f\"Date range: {price_data.index[0]} to {price_data.index[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKQJZUx8smAB"
      },
      "source": [
        "# Uploading Data CSV from repo so we always have it and dont have to manually import\n",
        "Michelle's addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8X3zmLAslA5",
        "outputId": "5dd86327-5895-4321-9124-ed3c83a6180c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CP322-Final-Project-Group-9'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 35 (delta 8), reused 12 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 345.71 KiB | 4.49 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "[Errno 2] No such file or directory: '/content/CP322-Final-Project-Group-9'\n",
            "/Users/jaypatel/Desktop/Projects/CP322-Final-Project-Group-9\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/submarinejuice/CP322-Final-Project-Group-9\"\n",
        "REPO_NAME = \"CP322-Final-Project-Group-9\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    # First time in this Colab session: clone the repo\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    # Repo already there in this runtime: pull latest changes\n",
        "    %cd {REPO_NAME}\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "# Move into repo so relative paths work\n",
        "%cd /content/{REPO_NAME}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zHnE5G9tQLV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHgjKOa5tQe9",
        "outputId": "b6fa7c2c-95d8-4353-8534-e27724304f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current directory: /Users/jaypatel/Desktop/Projects/CP322-Final-Project-Group-9\n",
            "Repo contents: ['.DS_Store', 'cp322_FINAL.ipynb', 'DATASET', 'README.md', '.git']\n",
            "DATASET contents: ['AE_investment_dataset.csv']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30 entries, 0 to 29\n",
            "Columns: 364 entries, Participant_code to SCR_AnticipatoryS4_T10\n",
            "dtypes: float64(356), int64(5), object(3)\n",
            "memory usage: 85.4+ KB\n",
            "Participant_code\n",
            "Age\n",
            "Gender\n",
            "Nationality\n",
            "Ethnicity\n",
            "Played_stock_market\n",
            "Played_in_years\n",
            "Played_how_often\n",
            "Stock_amount_S1_T1\n",
            "Stock_amount_S1_T2\n",
            "Stock_amount_S1_T3\n",
            "Stock_amount_S1_T4\n",
            "Stock_amount_S1_T5\n",
            "Stock_amount_S1_T6\n",
            "Stock_amount_S1_T7\n",
            "Stock_amount_S1_T8\n",
            "Stock_amount_S1_T9\n",
            "Stock_amount_S1_T10\n",
            "Stock_amount_S2_T1\n",
            "Stock_amount_S2_T2\n",
            "Stock_amount_S2_T3\n",
            "Stock_amount_S2_T4\n",
            "Stock_amount_S2_T5\n",
            "Stock_amount_S2_T6\n",
            "Stock_amount_S2_T7\n",
            "Stock_amount_S2_T8\n",
            "Stock_amount_S2_T9\n",
            "Stock_amount_S2_T10\n",
            "Stock_amount_S3_T1\n",
            "Stock_amount_S3_T2\n",
            "Stock_amount_S3_T3\n",
            "Stock_amount_S3_T4\n",
            "Stock_amount_S3_T5\n",
            "Stock_amount_S3_T6\n",
            "Stock_amount_S3_T7\n",
            "Stock_amount_S3_T8\n",
            "Stock_amount_S3_T9\n",
            "Stock_amount_S3_T10\n",
            "Stock_amount_S4_T1\n",
            "Stock_amount_S4_T2\n",
            "Stock_amount_S4_T3\n",
            "Stock_amount_S4_T4\n",
            "Stock_amount_S4_T5\n",
            "Stock_amount_S4_T6\n",
            "Stock_amount_S4_T7\n",
            "Stock_amount_S4_T8\n",
            "Stock_amount_S4_T9\n",
            "Stock_amount_S4_T10\n",
            "Total_money_S1_T1\n",
            "Total_money_S1_T2\n",
            "Total_money_S1_T3\n",
            "Total_money_S1_T4\n",
            "Total_money_S1_T5\n",
            "Total_money_S1_T6\n",
            "Total_money_S1_T7\n",
            "Total_money_S1_T8\n",
            "Total_money_S1_T9\n",
            "Total_money_S1_T10\n",
            "Total_money_S2_T1\n",
            "Total_money_S2_T2\n",
            "Total_money_S2_T3\n",
            "Total_money_S2_T4\n",
            "Total_money_S2_T5\n",
            "Total_money_S2_T6\n",
            "Total_money_S2_T7\n",
            "Total_money_S2_T8\n",
            "Total_money_S2_T9\n",
            "Total_money_S2_T10\n",
            "Total_money_S3_T1\n",
            "Total_money_S3_T2\n",
            "Total_money_S3_T3\n",
            "Total_money_S3_T4\n",
            "Total_money_S3_T5\n",
            "Total_money_S3_T6\n",
            "Total_money_S3_T7\n",
            "Total_money_S3_T8\n",
            "Total_money_S3_T9\n",
            "Total_money_S3_T10\n",
            "Total_money_S4_T1\n",
            "Total_money_S4_T2\n",
            "Total_money_S4_T3\n",
            "Total_money_S4_T4\n",
            "Total_money_S4_T5\n",
            "Total_money_S4_T6\n",
            "Total_money_S4_T7\n",
            "Total_money_S4_T8\n",
            "Total_money_S4_T9\n",
            "Total_money_S4_T10\n",
            "Money_in_stocks_S1_T1\n",
            "Money_in_stocks_S1_T2\n",
            "Money_in_stocks_S1_T3\n",
            "Money_in_stocks_S1_T4\n",
            "Money_in_stocks_S1_T5\n",
            "Money_in_stocks_S1_T6\n",
            "Money_in_stocks_S1_T7\n",
            "Money_in_stocks_S1_T8\n",
            "Money_in_stocks_S1_T9\n",
            "Money_in_stocks_S1_T10\n",
            "Money_in_stocks_S2_T1\n",
            "Money_in_stocks_S2_T2\n",
            "Money_in_stocks_S2_T3\n",
            "Money_in_stocks_S2_T4\n",
            "Money_in_stocks_S2_T5\n",
            "Money_in_stocks_S2_T6\n",
            "Money_in_stocks_S2_T7\n",
            "Money_in_stocks_S2_T8\n",
            "Money_in_stocks_S2_T9\n",
            "Money_in_stocks_S2_T10\n",
            "Money_in_stocks_S3_T1\n",
            "Money_in_stocks_S3_T2\n",
            "Money_in_stocks_S3_T3\n",
            "Money_in_stocks_S3_T4\n",
            "Money_in_stocks_S3_T5\n",
            "Money_in_stocks_S3_T6\n",
            "Money_in_stocks_S3_T7\n",
            "Money_in_stocks_S3_T8\n",
            "Money_in_stocks_S3_T9\n",
            "Money_in_stocks_S3_T10\n",
            "Money_in_stocks_S4_T1\n",
            "Money_in_stocks_S4_T2\n",
            "Money_in_stocks_S4_T3\n",
            "Money_in_stocks_S4_T4\n",
            "Money_in_stocks_S4_T5\n",
            "Money_in_stocks_S4_T6\n",
            "Money_in_stocks_S4_T7\n",
            "Money_in_stocks_S4_T8\n",
            "Money_in_stocks_S4_T9\n",
            "Money_in_stocks_S4_T10\n",
            "PANAS_Initial_interested\n",
            "PANAS_Initial_distressed\n",
            "PANAS_Initial_excited\n",
            "PANAS_Initial_upset\n",
            "PANAS_Initial_strong\n",
            "PANAS_Initial_guilty\n",
            "PANAS_Initial_scared\n",
            "PANAS_Initial_hostile\n",
            "PANAS_Initial_enthusiastic\n",
            "PANAS_Initial_proud\n",
            "PANAS_Initial_irritable\n",
            "PANAS_Initial_alert\n",
            "PANAS_Initial_ashamed\n",
            "PANAS_Initial_inspired\n",
            "PANAS_Initial_nervous\n",
            "PANAS_Initial_determined\n",
            "PANAS_Initial_attentive\n",
            "PANAS_Initial_jittery\n",
            "PANAS_Initial_active\n",
            "PANAS_Initial_afraid\n",
            "PANAS_Initial_positive\n",
            "PANAS_Initial_negative\n",
            "PANAS_S1_interested\n",
            "PANAS_S1_distressed\n",
            "PANAS_S1_excited\n",
            "PANAS_S1_upset\n",
            "PANAS_S1_strong\n",
            "PANAS_S1_guilty\n",
            "PANAS_S1_scared\n",
            "PANAS_S1_hostile\n",
            "PANAS_S1_enthusiastic\n",
            "PANAS_S1_proud\n",
            "PANAS_S1_irritable\n",
            "PANAS_S1_alert\n",
            "PANAS_S1_ashamed\n",
            "PANAS_S1_inspired\n",
            "PANAS_S1_nervous\n",
            "PANAS_S1_determined\n",
            "PANAS_S1_attentive\n",
            "PANAS_S1_jittery\n",
            "PANAS_S1_active\n",
            "PANAS_S1_afraid\n",
            "PANAS_S1_positive\n",
            "PANAS_S1_negative\n",
            "PANAS_S2_interested\n",
            "PANAS_S2_distressed\n",
            "PANAS_S2_excited\n",
            "PANAS_S2_upset\n",
            "PANAS_S2_strong\n",
            "PANAS_S2_guilty\n",
            "PANAS_S2_scared\n",
            "PANAS_S2_hostile\n",
            "PANAS_S2_enthusiastic\n",
            "PANAS_S2_proud\n",
            "PANAS_S2_irritable\n",
            "PANAS_S2_alert\n",
            "PANAS_S2_ashamed\n",
            "PANAS_S2_inspired\n",
            "PANAS_S2_nervous\n",
            "PANAS_S2_determined\n",
            "PANAS_S2_attentive\n",
            "PANAS_S2_jittery\n",
            "PANAS_S2_active\n",
            "PANAS_S2_afraid\n",
            "PANAS_S2_positive\n",
            "PANAS_S2_negative\n",
            "PANAS_S3_interested\n",
            "PANAS_S3_distressed\n",
            "PANAS_S3_excited\n",
            "PANAS_S3_upset\n",
            "PANAS_S3_strong\n",
            "PANAS_S3_guilty\n",
            "PANAS_S3_scared\n",
            "PANAS_S3_hostile\n",
            "PANAS_S3_enthusiastic\n",
            "PANAS_S3_proud\n",
            "PANAS_S3_irritable\n",
            "PANAS_S3_alert\n",
            "PANAS_S3_ashamed\n",
            "PANAS_S3_inspired\n",
            "PANAS_S3_nervous\n",
            "PANAS_S3_determined\n",
            "PANAS_S3_attentive\n",
            "PANAS_S3_jittery\n",
            "PANAS_S3_active\n",
            "PANAS_S3_afraid\n",
            "PANAS_S3_positive\n",
            "PANAS_S3_negative\n",
            "PANAS_S4_interested\n",
            "PANAS_S4_distressed\n",
            "PANAS_S4_excited\n",
            "PANAS_S4_upset\n",
            "PANAS_S4_strong\n",
            "PANAS_S4_guilty\n",
            "PANAS_S4_scared\n",
            "PANAS_S4_hostile\n",
            "PANAS_S4_enthusiastic\n",
            "PANAS_S4_proud\n",
            "PANAS_S4_irritable\n",
            "PANAS_S4_alert\n",
            "PANAS_S4_ashamed\n",
            "PANAS_S4_inspired\n",
            "PANAS_S4_nervous\n",
            "PANAS_S4_determined\n",
            "PANAS_S4_attentive\n",
            "PANAS_S4_jittery\n",
            "PANAS_S4_active\n",
            "PANAS_S4_afraid\n",
            "PANAS_S4_positive\n",
            "PANAS_S4_negative\n",
            "stock_fluctuation_S1_T2\n",
            "stock_fluctuation_S1_T3\n",
            "stock_fluctuation_S1_T4\n",
            "stock_fluctuation_S1_T5\n",
            "stock_fluctuation_S1_T6\n",
            "stock_fluctuation_S1_T7\n",
            "stock_fluctuation_S1_T8\n",
            "stock_fluctuation_S1_T9\n",
            "stock_fluctuation_S1_T10\n",
            "stock_fluctuation_S2_T2\n",
            "stock_fluctuation_S2_T3\n",
            "stock_fluctuation_S2_T4\n",
            "stock_fluctuation_S2_T5\n",
            "stock_fluctuation_S2_T6\n",
            "stock_fluctuation_S2_T7\n",
            "stock_fluctuation_S2_T8\n",
            "stock_fluctuation_S2_T9\n",
            "stock_fluctuation_S2_T10\n",
            "stock_fluctuation_S3_T2\n",
            "stock_fluctuation_S3_T3\n",
            "stock_fluctuation_S3_T4\n",
            "stock_fluctuation_S3_T5\n",
            "stock_fluctuation_S3_T6\n",
            "stock_fluctuation_S3_T7\n",
            "stock_fluctuation_S3_T8\n",
            "stock_fluctuation_S3_T9\n",
            "stock_fluctuation_S3_T10\n",
            "stock_fluctuation_S4_T2\n",
            "stock_fluctuation_S4_T3\n",
            "stock_fluctuation_S4_T4\n",
            "stock_fluctuation_S4_T5\n",
            "stock_fluctuation_S4_T6\n",
            "stock_fluctuation_S4_T7\n",
            "stock_fluctuation_S4_T8\n",
            "stock_fluctuation_S4_T9\n",
            "stock_fluctuation_S4_T10\n",
            "Mean_Return_S1_T2\n",
            "Mean_Return_S1_T3\n",
            "Mean_Return_S1_T4\n",
            "Mean_Return_S1_T5\n",
            "Mean_Return_S1_T6\n",
            "Mean_Return_S1_T7\n",
            "Mean_Return_S1_T8\n",
            "Mean_Return_S1_T9\n",
            "Mean_Return_S1_T10\n",
            "Mean_Return_S2_T2\n",
            "Mean_Return_S2_T3\n",
            "Mean_Return_S2_T4\n",
            "Mean_Return_S2_T5\n",
            "Mean_Return_S2_T6\n",
            "Mean_Return_S2_T7\n",
            "Mean_Return_S2_T8\n",
            "Mean_Return_S2_T9\n",
            "Mean_Return_S2_T10\n",
            "Mean_Return_S3_T2\n",
            "Mean_Return_S3_T3\n",
            "Mean_Return_S3_T4\n",
            "Mean_Return_S3_T5\n",
            "Mean_Return_S3_T6\n",
            "Mean_Return_S3_T7\n",
            "Mean_Return_S3_T8\n",
            "Mean_Return_S3_T9\n",
            "Mean_Return_S3_T10\n",
            "Mean_Return_S4_T2\n",
            "Mean_Return_S4_T3\n",
            "Mean_Return_S4_T4\n",
            "Mean_Return_S4_T5\n",
            "Mean_Return_S4_T6\n",
            "Mean_Return_S4_T7\n",
            "Mean_Return_S4_T8\n",
            "Mean_Return_S4_T9\n",
            "Mean_Return_S4_T10\n",
            "Overall_mean_return_percentage\n",
            "Total_return_S1\n",
            "Total_return_S2\n",
            "Total_return_S3\n",
            "Total_return_S4\n",
            "Overall_Total_return\n",
            "Residual_PANAS_S1_positive\n",
            "Residual_PANAS_S2_positive\n",
            "Residual_PANAS_S3_positive\n",
            "Residual_PANAS_S4_positive\n",
            "Residual_PANAS_S1_negative\n",
            "Residual_PANAS_S2_negative\n",
            "Residual_PANAS_S3_negative\n",
            "Residual_PANAS_S4_negative\n",
            "SCR_AnticipatoryS1_T1\n",
            "SCR_AnticipatoryS1_T2\n",
            "SCR_AnticipatoryS1_T3\n",
            "SCR_AnticipatoryS1_T4\n",
            "SCR_AnticipatoryS1_T5\n",
            "SCR_AnticipatoryS1_T6\n",
            "SCR_AnticipatoryS1_T7\n",
            "SCR_AnticipatoryS1_T8\n",
            "SCR_AnticipatoryS1_T9\n",
            "SCR_AnticipatoryS1_T10\n",
            "SCR_AnticipatoryS2_T1\n",
            "SCR_AnticipatoryS2_T2\n",
            "SCR_AnticipatoryS2_T3\n",
            "SCR_AnticipatoryS2_T4\n",
            "SCR_AnticipatoryS2_T5\n",
            "SCR_AnticipatoryS2_T6\n",
            "SCR_AnticipatoryS2_T7\n",
            "SCR_AnticipatoryS2_T8\n",
            "SCR_AnticipatoryS2_T9\n",
            "SCR_AnticipatoryS2_T10\n",
            "SCR_AnticipatoryS3_T1\n",
            "SCR_AnticipatoryS3_T2\n",
            "SCR_AnticipatoryS3_T3\n",
            "SCR_AnticipatoryS3_T4\n",
            "SCR_AnticipatoryS3_T5\n",
            "SCR_AnticipatoryS3_T6\n",
            "SCR_AnticipatoryS3_T7\n",
            "SCR_AnticipatoryS3_T8\n",
            "SCR_AnticipatoryS3_T9\n",
            "SCR_AnticipatoryS3_T10\n",
            "SCR_AnticipatoryS4_T1\n",
            "SCR_AnticipatoryS4_T2\n",
            "SCR_AnticipatoryS4_T3\n",
            "SCR_AnticipatoryS4_T4\n",
            "SCR_AnticipatoryS4_T5\n",
            "SCR_AnticipatoryS4_T6\n",
            "SCR_AnticipatoryS4_T7\n",
            "SCR_AnticipatoryS4_T8\n",
            "SCR_AnticipatoryS4_T9\n",
            "SCR_AnticipatoryS4_T10\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "print(\"Repo contents:\", os.listdir())\n",
        "print(\"DATASET contents:\", os.listdir(\"DATASET\"))\n",
        "\n",
        "df = pd.read_csv(\"DATASET/AE_investment_dataset.csv\")\n",
        "df.head()\n",
        "df.info()\n",
        "df.isna().mean().sort_values().head(20)\n",
        "df.columns.tolist()\n",
        "for c in df.columns:\n",
        "    print(c)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPuQaXQjy8wf"
      },
      "source": [
        "##Quick note bc I didn't know what PANAS meant:\n",
        "- PANAS refers to the Positive and Negative Affect Schedule, a widely used psychological scale that measures an individual's mood by assessing both positive and negative emotions. Developed in 1988 by Watson, Clark, and Tellegen, it's a 20-item self-report measure used in research and clinical settings to gauge how frequently someone experiences emotions like interest, joy, enthusiasm (positive affect) versus feelings of distress, sadness, and nervousness (negative affect).\n",
        "## How it works\n",
        "- 20 items: The scale consists of 20 words that describe different feelings and emotions.\n",
        "- Two dimensions: These items are separated into two subscales: one for positive affect (PA) and one for negative affect (NA).\n",
        "- Rating scale: Participants rate how they felt about each item over a specific time frame (e.g., \"right now,\" \"today,\" \"over the past few weeks\") on a 5-point scale.\n",
        "- Scoring: Each positive and negative item is scored individually. The total positive score and total negative score are then calculated. A higher positive score indicates more positive affect, while a higher negative score indicates more negative affect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJg0a9hQw5Q5"
      },
      "source": [
        "Building a per-trial table with:\n",
        "1. inputs per step:\n",
        "  - money_in_stocks\n",
        "  - mean_return\n",
        "  - stock_fluctuation\n",
        "  - scr_anticipatory\n",
        "2. Static inputs:\n",
        "3. Target\n",
        "  - Whether they invested in the stock (money_in_stocks > 0 -> 1 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HIru1DWw3fz",
        "outputId": "59abf963-a86c-4f57-c27a-bfbb29edf8ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_stock_cols: 40\n",
            "n_scr_cols: 40\n",
            "n_return_cols: 36\n",
            "n_fluctuation_cols: 36\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# 1. ID & static columns we carry along\n",
        "id_cols = [\"Participant_code\", \"Age\", \"Gender\", \"Nationality\", \"Ethnicity\", \"Played_stock_market\"]\n",
        "\n",
        "# 2. Find all trial-level columns by prefix\n",
        "stock_cols = [c for c in df.columns if c.startswith(\"Money_in_stocks_S\")]\n",
        "scr_cols   = [c for c in df.columns if c.startswith(\"SCR_AnticipatoryS\")]\n",
        "ret_cols   = [c for c in df.columns if c.startswith(\"Mean_Return_S\")]\n",
        "fluc_cols  = [c for c in df.columns if c.startswith(\"stock_fluctuation_S\")]\n",
        "\n",
        "print(\"n_stock_cols:\", len(stock_cols))\n",
        "print(\"n_scr_cols:\", len(scr_cols))\n",
        "print(\"n_return_cols:\", len(ret_cols))\n",
        "print(\"n_fluctuation_cols:\", len(fluc_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example stock cols: ['Money_in_stocks_S1_T1', 'Money_in_stocks_S1_T2', 'Money_in_stocks_S1_T3', 'Money_in_stocks_S1_T4', 'Money_in_stocks_S1_T5']\n",
            "Example SCR cols: ['SCR_AnticipatoryS1_T1', 'SCR_AnticipatoryS1_T2', 'SCR_AnticipatoryS1_T3', 'SCR_AnticipatoryS1_T4', 'SCR_AnticipatoryS1_T5']\n",
            "Example return cols: ['Mean_Return_S1_T2', 'Mean_Return_S1_T3', 'Mean_Return_S1_T4', 'Mean_Return_S1_T5', 'Mean_Return_S1_T6']\n",
            "Example fluctuation cols: ['stock_fluctuation_S1_T2', 'stock_fluctuation_S1_T3', 'stock_fluctuation_S1_T4', 'stock_fluctuation_S1_T5', 'stock_fluctuation_S1_T6']\n"
          ]
        }
      ],
      "source": [
        "print(\"Example stock cols:\", stock_cols[:5])\n",
        "print(\"Example SCR cols:\", scr_cols[:5])\n",
        "print(\"Example return cols:\", ret_cols[:5])\n",
        "print(\"Example fluctuation cols:\", fluc_cols[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting the Wide Table -> Long Table\n",
        "Wide format, each participant has \n",
        "- 40 stock invesment columns\n",
        "- 40 anticipatroy SCR columns\n",
        "- Matching retunr and fluctiation columns\n",
        "\n",
        "not the best for our ml model\n",
        "\n",
        "since the model expects one row = one sample, columns = features, one target lable per row\n",
        "\n",
        "wide -> long\n",
        "each row = one trail decision \n",
        "paricipant attributes are copied over (age, gender, etc.)\n",
        "trial-levels features are included\n",
        "\n",
        "so the dataset goes from 30 rows to 1200 rows, giving us enough samples to train the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Participant_code  Age  Gender  Nationality  Ethnicity Played_stock_market  \\\n",
            "0                 1   22       2            4          6                   1   \n",
            "1                 1   22       2            4          6                   1   \n",
            "2                 1   22       2            4          6                   1   \n",
            "3                 1   22       2            4          6                   1   \n",
            "4                 1   22       2            4          6                   1   \n",
            "\n",
            "   game  trial  money_in_stocks    scr  mean_return  stock_fluctuation  \n",
            "0     1      1          16884.0  0.806          NaN                NaN  \n",
            "1     1      2           7623.2  0.028        0.045                2.0  \n",
            "2     1      3           5941.6  0.232       -0.046                1.0  \n",
            "3     1      4          31265.0  0.954        0.370                2.0  \n",
            "4     1      5           3494.8  0.000        0.046                2.0  \n",
            "(1200, 12)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "records = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    # static participant info\n",
        "    base = row[id_cols].to_dict()\n",
        "    \n",
        "    for stock_col in stock_cols:\n",
        "        # match the S1_T1 part AFTER \"Money_in_stocks_\"\n",
        "        m = re.search(r\"Money_in_stocks_(S\\d+_T\\d+)\", stock_col)\n",
        "        if m is None:\n",
        "            continue\n",
        "        \n",
        "        tag = m.group(1)              # e.g. \"S1_T1\"\n",
        "        game = int(tag.split(\"_\")[0][1:])   # \"S1\" -> 1\n",
        "        trial = int(tag.split(\"_\")[1][1:])  # \"T1\" -> 1\n",
        "        \n",
        "        money_in_stocks = row[stock_col]\n",
        "        \n",
        "        # build matching column names for other signals using the same tag\n",
        "        scr_col  = f\"SCR_Anticipatory{tag}\"       # SCR_AnticipatoryS1_T1\n",
        "        ret_col  = f\"Mean_Return_{tag}\"           # Mean_Return_S1_T1\n",
        "        fluc_col = f\"stock_fluctuation_{tag}\"     # stock_fluctuation_S1_T1\n",
        "        \n",
        "        rec = {\n",
        "            **base,\n",
        "            \"game\": game,\n",
        "            \"trial\": trial,\n",
        "            \"money_in_stocks\": money_in_stocks,\n",
        "            \"scr\": row.get(scr_col, np.nan),\n",
        "            \"mean_return\": row.get(ret_col, np.nan),\n",
        "            \"stock_fluctuation\": row.get(fluc_col, np.nan),\n",
        "        }\n",
        "        records.append(rec)\n",
        "\n",
        "long_df = pd.DataFrame(records)\n",
        "print(long_df.head())\n",
        "print(long_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "High vs Low Investment \n",
        "1 = high invesment\n",
        "0 = low invesment\n",
        "splits the resulits in a balance data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "high_invest\n",
              "1    0.5\n",
              "0    0.5\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold = long_df[\"money_in_stocks\"].median()\n",
        "long_df[\"high_invest\"] = (long_df[\"money_in_stocks\"] >= threshold).astype(int)\n",
        "\n",
        "long_df[\"high_invest\"].value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline Model 1 Logistic Regression\n",
        "Predicts whether a patricipant makes a hihg vs. low invsment on each trial\n",
        "\n",
        "We use a smalls et of market and physiology-based features\n",
        "- game - four stock-market games the trial belongs to\n",
        "- trial - number withing the game\n",
        "- scr \n",
        "- mean_return - expected return of the stock\n",
        "- stock_fluctuation - volatitlity condition of the trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6375\n",
            "F1: 0.6533864541832669\n",
            "AUC: 0.710902777777778\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "feature_cols = [\"game\", \"trial\", \"scr\", \"mean_return\", \"stock_fluctuation\"]\n",
        "\n",
        "# 1. Drop rows where the label itself is missing (shouldnâ€™t be, but just in case)\n",
        "long_df_clean = long_df.dropna(subset=[\"high_invest\"])\n",
        "\n",
        "X = long_df_clean[feature_cols]\n",
        "y = long_df_clean[\"high_invest\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Preprocessing: impute missing values, then scale\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, feature_cols),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "# 3. Logistic Regression pipeline\n",
        "logreg = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", LogisticRegression(max_iter=1000)),\n",
        "])\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1:\", f1_score(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline Model 2 Random Forest\n",
        "\n",
        "Random Forest can capture non-linear interactions between market\n",
        "variables and physiological signals. This gives us a stronger,\n",
        "tree-based baseline to compare against our later neuroscience-inspired\n",
        "feature engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF Accuracy: 0.9333333333333333\n",
            "RF F1: 0.9316239316239316\n",
            "RF AUC: 0.9875694444444445\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),  # same imputer + scaler as before\n",
        "    (\"model\", RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"RF Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"RF F1:\", f1_score(y_test, y_pred_rf))\n",
        "print(\"RF AUC:\", roc_auc_score(y_test, y_prob_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Random Tree vs Logistic Regression\n",
        "Logistic (Linear Model)\n",
        "Random Tree (Non-Linear, tree-based model)\n",
        "\n",
        "Both Models use the same feature set\n",
        "- game \n",
        "- trial\n",
        "- scr\n",
        "- mean_return\n",
        "- stock_fluctuation\n",
        "\n",
        "Metrics\n",
        "- Accuracy\n",
        "- F1 Score\n",
        "- AUC (Area Under ROC Curve) - ability to seperate high vs low investments\n",
        "\n",
        "Interpertation\n",
        "- Random Forest outperforms Logistic \n",
        "Which shows\n",
        "- Decisions are influenced by non-linear interactions\n",
        "- SCR interacts with the market in more complex ways\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'long_df_clean' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ---- Build temporal_df with SCR history features ----\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Start from the cleaned long_df (so label isn't missing)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m temporal_df = \u001b[43mlong_df_clean\u001b[49m.sort_values(\n\u001b[32m      5\u001b[39m     [\u001b[33m\"\u001b[39m\u001b[33mParticipant_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgame\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtrial\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m ).copy()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Group by participant so lags/rolling stay within a person\u001b[39;00m\n\u001b[32m      9\u001b[39m grp = temporal_df.groupby(\u001b[33m\"\u001b[39m\u001b[33mParticipant_code\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'long_df_clean' is not defined"
          ]
        }
      ],
      "source": [
        "# ---- Build temporal_df with SCR history features ----\n",
        "\n",
        "# Start from the cleaned long_df (so label isn't missing)\n",
        "temporal_df = long_df_clean.sort_values(\n",
        "    [\"Participant_code\", \"game\", \"trial\"]\n",
        ").copy()\n",
        "\n",
        "# Group by participant so lags/rolling stay within a person\n",
        "grp = temporal_df.groupby(\"Participant_code\")\n",
        "\n",
        "# 1-step lag of SCR\n",
        "temporal_df[\"scr_lag1\"] = grp[\"scr\"].shift(1)\n",
        "\n",
        "# Change from previous trial\n",
        "temporal_df[\"scr_delta1\"] = temporal_df[\"scr\"] - temporal_df[\"scr_lag1\"]\n",
        "\n",
        "# Rolling mean of SCR over last 3 trials (short-term trend)\n",
        "temporal_df[\"scr_roll_mean3\"] = grp[\"scr\"].transform(\n",
        "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "# Replace NaNs from first trials with 0.0\n",
        "for col in [\"scr_lag1\", \"scr_delta1\", \"scr_roll_mean3\"]:\n",
        "    temporal_df[col] = temporal_df[col].fillna(0.0)\n",
        "\n",
        "print(\"temporal_df shape:\", temporal_df.shape)\n",
        "print(temporal_df[[\"Participant_code\", \"game\", \"trial\",\n",
        "                   \"scr\", \"scr_lag1\", \"scr_delta1\", \"scr_roll_mean3\",\n",
        "                   \"high_invest\"]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'temporal_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Same feature sets as before\u001b[39;00m\n\u001b[32m      8\u001b[39m feature_sets = {\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMarket only\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mmean_return\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstock_fluctuation\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSCR dynamics only\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mscr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mscr_lag1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mscr_delta1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mscr_roll_mean3\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     ],\n\u001b[32m     15\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m y = \u001b[43mtemporal_df\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mhigh_invest\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_rf\u001b[39m(feature_cols, name):\n\u001b[32m     20\u001b[39m     X = temporal_df[feature_cols].values\n",
            "\u001b[31mNameError\u001b[39m: name 'temporal_df' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# Same feature sets as before\n",
        "feature_sets = {\n",
        "    \"Market only\": [\"mean_return\", \"stock_fluctuation\"],\n",
        "    \"SCR dynamics only\": [\"scr\", \"scr_lag1\", \"scr_delta1\", \"scr_roll_mean3\"],\n",
        "    \"Market + SCR dynamics\": [\n",
        "        \"mean_return\", \"stock_fluctuation\",\n",
        "        \"scr\", \"scr_lag1\", \"scr_delta1\", \"scr_roll_mean3\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "y = temporal_df[\"high_invest\"].values\n",
        "\n",
        "def run_rf(feature_cols, name):\n",
        "    X = temporal_df[feature_cols].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Scaling isn't strictly needed for trees, but keeping pipeline structure is okay\n",
        "    rf = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"rf\", RandomForestClassifier(\n",
        "            n_estimators=300,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\n=== Random Forest â€“ {name} ===\")\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
        "    print(\"F1:\",       round(f1_score(y_test, y_pred), 3))\n",
        "    print(\"AUC:\",      round(roc_auc_score(y_test, y_prob), 3))\n",
        "\n",
        "\n",
        "for name, cols in feature_sets.items():\n",
        "    run_rf(cols, name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
